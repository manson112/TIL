# 3장 카프카 기본 개념과 구조

# 3.1 카프카 기초 다지기

## 카프카를 구성하는 주요 요소

| 주키퍼(ZooKeeper) | 카프카의 메타데이터 관리 및 브로커의 정상상태 점검을 담당하는 아파치 프로젝트 애플리케이션  |
| --- | --- |
| 카프카 또는 카프카 클러스터 | 여러대의 카프카 브로커를 구성한 클러스터 |
| 브로커(Broker) | 카프카 애플리케이션이 설치된 서버 또는 노드 |
| 프로듀서(Producer) | 카프카로 메시지를 보내는 역할을 하는 클라이언트를 총칭 |
| 컨슈머(Consumer) | 카프카에서 메시지를 꺼내가는 역할을 하는 클라이언트를 총칭 |
| 토픽(Topic) | 카프카는 메시지 피드들을 토픽으로 구분하고, 각 토픽의 이름은 카프카 내에서 고유하다 |
| 파티션(Partition) | 병렬 처리 및 고성능을 얻기 위해 하나의 토픽을 여러 개로 나눈 것 |
| 세그먼트(Segment) | 프로듀서가 전송한 실제 메시지가 브로커의 로컬 디스크에 저장되는 파일 |
| 메시지(Message) 또는 레코드(Record) | 프로듀서가 브로커로 전송하거나 컨슈머가 읽어가는 데이터 조각 |

## 3.1.1 리플리케이션 (Replication)

각 메시지들을 여러 개로 복제해서 카프카 클러스터 내 브로커들에 분산시키는 동작을 의미합니다. 덕분에 하나의 브로커가 종료되더라도 카프카는 안정성을 유지할 수 있습니다.

```bash
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server peter-kafka01.foo.bar:9092 --create --topic peter
-overview01 --partitions 1 --replication-factor 3
```

위 명령어는 카프카 내에 원본을 포함하여 3개의 replication을 유지하겠다는 의미를 가집니다. 정확하게는 토픽이 리플리케이션 되는것이 아니라 토픽의 파티션이 리플리케이션되는 것입니다.

리플리케이션 팩터 수가 커지면 안정성은 높아지지만 그만큼 브로커 리소스를 많이 사용하게 됩니다. 따라서 복제에 대한 오버헤드를 줄여서 최대한 브로커를 효율적으로 사용하는 것을 권장합니다.

- 테스트나 개발 환경: —replication-factor 1
- 운영 환경(로그성 메시지로서 약간의 유실 허용): —replication-factor 2
- 운영 환경(유실 허용하지 않음): —replication-factor 3

리플리케이션 팩터 수를 4 또는 5 이상으로 설정할 수도 있지만, 3일 경우에 충분히 메시지 안정성도 보장하고 적절한 디스크 공간을 사용할 수 있습니다.

## 3.1.2 파티션 (Partition)

하나의 토픽이 한 번에 처리할 수 있는 한계를 높이기 위해 토픽 하나를 여러 개로 나눠 병렬처리가 가능하게 만든 것입니다. 이렇게 나누면 분산처리도 가능하고 나뉜 수만큼 컨슈머를 연결할 수 있습니다.

파티션 번호는 0부터 시작합니다.

파티션 수도 토픽을 생성할 때 옵션으로 설정하게 되는데, 파티션 수를 정하는 기준은 다소 모호한 경우가 많습니다.

각 메시지 크기나 초당 메시지 건수 등에 따라 달라지므로 정확하게 예측하기는 어렵습니다.

파티션 수는 초기 생성후 늘릴 수 있지만, 한 번 늘린 파티션 수는 절대로 줄일 수 없습니다. 

따라서 초기에는 파티션 수를 작게 생성한 후 메시지 처리량이나 컨슈머의 LAG 등을 모니터링 하면서 조금씩 늘려가는 방법이 가장 좋습니다.

(LAG: 프로듀서가 보낸 메시지 수 - 컨슈머가 가져간 메시지 수)

## 3.1.3 세그먼트 (Segment)

프로듀서에 의해 브로커로 전송된 메시지는 토픽의 파티션에 저장되며, 각 메시지들은 세그먼트라는 로그 파일의 형태로 브로커의 로컬 디스크에 저장됩니다.

각 파티션마다 N개의 세그먼트 로그 파일들이 존재합니다.

```bash
ls /data/kafka-logs 

[결과]
peter-overview01-0 디렉토리 존재
```

peter-overview01-0 디렉토리는 peter-overview01 토픽의 0번 파티션 디렉토리를 의미합니다.

이 디렉토리 내부의 0000000.log 파일을 hexdump를 보여주는 xxd 명령어를 사용해서 살펴보면 Producer를 통해 보낸 메시지를 확인할 수 있습니다.

1. 프로듀서는 카프카의 peter-overview01 토픽으로 메시지를 전송합니다.
2. peter-overview01 토픽은 파티션이 하나 뿐이므로, 프로듀서로부터 받은 메시지를 파티션0의 세그먼트 로그 파일에 저장합니다.
3. 브로커의 세그먼트 로그 파일에 저장된 메시지는 컨슈머가 읽어갈 수 있습니다.

# 3.2 카프카의 핵심 개념

카프카가 인기있는 이유는 카프카의 높은 처리량, 빠른 응답 속도, 안정성 때문입니다. 하지만 왜 카프카가 그렇게 안정적인지, 어떻게 높은 처리량을 갖게 되었는지 파고들려고 합니다.

## 3.2.1 분산 시스템

분산 시스템은 네트워크 상에서 연결된 컴퓨터들의 그룹을 말하며, 단일 시스템이 갖지 못한 높은 성능을 목표로 합니다. 이러한 분산 시스템은 성능이 높다는 장점 이외에 하나의 서버 또는 노드 등에 장애가 발생할 때 다른 서버 또는 노드가 대신 처리하므로 장애 대응이 탁월하며, 부하가 높은 경우에는 시스템 확장이 용이하다는 장점도 있습니다. 

카프카도 최초 구성한 클러스터의 리소스가 한계치에 도달해 더욱 높은 메시지 처리량이 필요한 경우, 브로커를 추가하는 방식으로 확장이 가능합니다.

## 3.2.2 페이지 캐시

카프카는 **높은 처리량**을 얻기 위해 몇 가지 기능을 추가했는데, 그중 대표적인 것이 바로 페이지 캐시의 이용입니다.

OS의 페이지 캐시를 활용하는 방식으로 설계되어 있으며 직접 디스크에 읽고 쓰는 대신 물리 메모리 중 애플리케이션이 사용하지 않는 일부 잔여 메모리를 활용합니다. 

이를 이용하면 디스크 I/O에 대한 접근이 줄어들어 성능을 높일 수 있습니다. 카프카는 직접 디스크에서 읽고 쓰기를 하지 않고 페이지 캐시를 통해 읽고 쓰기를 한다고 이해하면 됩니다.

## 3.2.3 배치 전송 처리

카프카는 프로듀서, 컨슈머 클라이언트들과 서로 통신하며 메시지를 주고받을 때 배치전송을 권장하며 이를 통해 단건으로 통신할 때에 비해 네트워크 오버헤드를 줄일 수 있을뿐만 아니라 장기적으로는 더욱 **빠르고 효율적**으로 처리할 수 있습니다.

 

## 3.2.4 압축 전송

카프카는 메시지 전송 시 좀 더 성능이 높은 압축 전송을 사용하는 것을 권장합니다. (gzip, snappy, lz4, zstd 등을 지원)

압축만으로도 네트워크 대역폭이나 회선 비용 등을 줄일 수 있는데, 배치 전송과 결합해 사용한다면 더욱 높은 효과를 얻게 됩니다.

압축 타입에 따라 약간의 특성이 있어서, 일반적으로 높은 압축률이 필요하다면 gzip이나 zstd를 권장하고, 빠른 응답 속도가 필요하다면 lz4나 snappy를 권장합니다. 

## 3.2.5 토픽, 파티션, 오프셋

카프카는 토픽에 데이터를 저장하는데, 토픽은 병렬 처리를 위해 여러 개의 파티션이라는 단위로 다시 나뉩니다. 카프카에서는 이와 같은 파티셔닝을 통해 단 하나의 토픽이라도 높은 처리량을 수행할 수 있습니다. 

파티션의 메시지가 저장되는 위치를 오프셋이라고 부르며, 오프셋은 순차적으로 증가하는 숫자(64비트) 형태로 되어 있습니다.

## 3.2.6 고가용성 보장

카프카는 분산 시스템이기 때문에 하나의 서버나 노드가 다운되어도 다른 서버 또는 노드가 장애가 발생한 서버의 역할을 대신해 안정적인 서비스가 가능합니다. 이러한 고가용성을 보장하기 위해 리플리케이션 기능이 제공됩니다. 

카프카에서 제공하는 리플리케이션 기능은 토픽 자체를 복제하는 것이 아니라 토픽의 파티션을 복제하는 것입니다. 원본과 리플리케이션을 구분하기 위해 흔히 마스터, 미러 같은 용어를 사용하는데 카프카에서는 리더(Leader)와 팔로워(Follower)라고 부릅니다.

리더는 1개로 유지하고 팔로워를 늘리는데, 팔로워의 수만큼 브로커의 디스크 공간도 소비되므로 이상적인 리플리케이션 팩터 수를 유지해야 하며, 일반적으로 3개로 구성하도록 권장합니다. 

리더는 프로듀서, 컨슈머로부터 오는 모든 읽기와 쓰기 요청을 처리하며, 팔로워는 오직 리더로부터 리플리케이션 하게 됩니다. 

## 3.2.7 주키퍼의 의존성

주키퍼는 하둡의 서브 프로젝트 중 하나로 추랍ㄹ해 2011년 아파치의 탑레벨 프로젝트로 승격됐습니다. 

주키퍼는 여러 대의 서버를 앙상블(클러스터)로 구성하고, 살아 있는 노드 수가 과반수 이상 유지된다면 지속적인 서비스가 가능한 구조입니다. 따라서 주키퍼는 반드시 홀수로 구성해야 합니다.

znode를 이용해 카프카의 메타 정보가 주키퍼에 기록되며, 주키퍼는 이러한 znode를 이용해 브로커의 노트 관리, 토픽 관리, 컨트롤러 관리 등 매우 중요한 역할을 하고 있습니다.

# 3.3 프로듀서의 기본 동작과 예제 맛보기

## 3.3.1 프로듀서 디자인

![Untitled](./3%EC%9E%A5%20%EC%B9%B4%ED%94%84%EC%B9%B4%20%EA%B8%B0%EB%B3%B8%20%EA%B0%9C%EB%85%90%EA%B3%BC%20%EA%B5%AC%EC%A1%B0/Untitled.png)

- ProducerRecord: 카프카로 전송하기 위한 실제 데이터이며, 토픽, 파티션, 키, 밸류로 구성됩니다. 토픽과 밸류는 필수값이며, 특정 파티션에 레코드들을 정렬하기 위한 레코드의 키는 선택사항입니다.
- send() 메소드를 통해 Serializer, Partitioner를 거치게 됩니다. 프로듀서 레코드에 파티션을 지정했다면, 파티셔너는 아무 동작도 하지 않고 지정된 파티션을 레코드를 전달합니다. 파티션을 지정하지 않은 경우에는 키를 가지고 파티션을 선택해 레코드를 전달하는데, 기본적으로는 라운드 로빈 방식으로 동작합니다.
- 프로듀서 내부에서는 send() 메소드 동작 이후 레코드들을 파티션별로 잠시 모아두게 되는데, 이는 프로듀서가 카프카로 전송하기 전, 배치 전송을 하기 위합입니다. 전송이 실패하면 재시도 동작이 이뤄지고, 지정한 횟수만큼 재시도가 실패하면 최종 실패를 전달하며, 전송이 성공하면 메타 데이터를 리턴하게 됩니다.

## 3.3.2 프로듀서의 주요 옵션

| 프로듀서 옵션 | 설명 |
| --- | --- |
| bootstrap.servers | 클라이언트가 카프카 클러스터에 처음 연결하기 위한 호스트와 포트 정보. 카프카 클러스터는 클러스터 마스터라는 개념이 없으므로, 클러스터 내 모든 서버가 클라이언트의 요청을 바랄 수 있습니다. |
| client.dns.lookup | 하나의 호스트에 여러 IP를 매핑해 사용하는 일부 환경에서 클라이언트가 하나의 IP와 연결하지 못할 경우 다른 IP로 시도하는 설정 |
| acks | 프로듀서가 카프카 토픽의 리더 측에 메시지를 전송한 후 요청을 완료하기를 결정하는 옵션입니다.
0, 1, all(-1)로 표현하며, 0은 빠른 전송을 의미하지만 일부 메시지 손실 가능성이 있고 1은 리더가 메시지를 받았는지 확인하지만 모든 팔로워를 전부 확인하지는 않습니다. all은 팔로워가 메시지를 받았는지 여부를 확인합니다. 다소 느릴 수는 있지만, 하나의 팔로워가 있는 한 메시지는 손실되지 않습니다. |
| buffer.memory | 프로듀서가 카프카 서버로 데이터를 보내기 위해 잠시 대기할 수 있는 전체 메모리 바이트 입니다. |
| compression.type | 프로듀서가 메시지 전송 시 선택할 수 있는 압축 타입입니다. (none, gzip, snappy, lz4, zstd) |
| enable.idempotence | 설정을 true로 하는 경우 중복 없는 전송이 가능하며 이와 동시에 max.in.flight.requests.per.connection은 5이하, retries는 0이상, acks 는 all로 설정해야 합니다. |
| max.in.flight.requests.per.connection | 하나의 커넥션에서 프로듀서가 최대한 ack 없이 전송할 수 있는 요청 수 입니다. 메시지의 순서가 중요하다면 1로 설정할 것을 권장하지만, 성능은 다소 떨어집니다. |
| retries | 일시적인 오류로 인해 전송에 실패한 데이터를 다시 보내는 횟수입니다. |
| batch.size | 프로듀서는 동일한 파티션으로 보내는 여러 데이터를 함께 배치로 보내려고 시도합니다. |
| linger.ms | 배치 형태의 메시지를 보내기 전에 추가적인메시지를 위해 기다리는 시간을 조정하고, 배치 크기에 도달하지 못한 상황에서 linger.ms 제한시간에 도달했을 때 메시지를 전송합니다. |
| transactional.id | Exactly Once를 위해 사용하는 옵션이며, 동일한 TransactionId에 한해 정확히 한 번을 보장합니다. 옵션을 사용하기 전 enable.idempotence를 true로 설정해야 합니다. |

## 3.3.3 프로듀서 예제

```bash
/usr/local/kafka/bin/kafka-topic.sh --bootstrap-server peter-kafka01.foo.bar:9092 --create 
--topic peter-basic01 --partitions 1 --replication-factor 3
```

프로듀서의 전송 방법은 ‘메시지를 보내고 확인하지 않기’, ‘동기 전송’, ‘비동기 전송’ 이라는 세 가지 방식으로크게 나눌 수 있습니다.

### 메세지를 보내고 확인하지 않기

```java
public class ProducerFireForgot {
	public static void main(String[] args) {
		Properties props = new Properties();
		props.put("bootstrap.servers", "peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092");
		props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
		props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
		
		Producer<String, String> producer = new KafkaProducer<>(props);

		try {
			for (int i=0; i<3; i++) {
				ProducerRecord<String, String> record = new ProducerRecord<>("peter-basic01", "MESSAGE - " + i);
				producer.send(record);
			}
		} catch (Exception e) {
			e.printstackTrace();
		} finally {
			producer.close();
		}
	}
	
}
```

### 동기 전송

```java
public class ProducerSync {
		public static void main(String[] args) {
			Properties props = new Properties();
			props.put("boprops.put("bootstrap.servers", "peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092");
			props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
			props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
		
			Producer<String, String> producer = new KafkaProducer<>(props);
			try {
				for (int i=0; i<3; i++) {
					ProducerRecord<String, String> record = new ProducerRecord<>("peter-basic01", "MESSAGE - " + i);
					RecordMetaData metadata = producer.send(record).get();
					System.out.printf("Topic: %s, Partition: %d, Offset: %d, Key: %s, Received Message: %s\n", 
														metaData.topic(), metadata.partition(), metadata.offset(), record.key(), record.value());
				}
			} catch (Exception e) {
				e.printstackTrace();
			} finally {
				producer.close();
			}
		}

}
```

프로듀서는 메시지를 보내고 send() 메소드의 Future 객체를 리턴하며, get() 메소드를 이용해 Future를 기다린 후 send()가 성공했는지 실패했는지 여부를 확인합니다. 

일단 ProducerRecord 전송이 성공하고 나면 RecordMetadata를 읽어 들여 파티션과 오프셋 정보를 확인할 수 있으며, 이 방법으로 메시지 전달의 성공 여부를 파악할 수 있습니다.

### 콜백 예제

```java
public class PeterProducerCallback implements Callback {
	private ProducerRecord<String, String> record;
	
	public PeterProducerCallback(ProducerRecord<String, String> record) {
		this.record = record;
	}
	
	@Override
	public void onCompletion(RecordMetadata metadata, Exception e) {
		if (e!= null) {
			e.printStackTrace();
		} else {
			System.out.printf("Topic: %s, Partition: %d, Offset: %d, Key: %s, Received Message: %s\n", 
														metaData.topic(), metadata.partition(), metadata.offset(), record.key(), record.value());
		}

	}
}

public class ProducerAsync {
	public static void main(String[] args) {
		Properties props = new Properties();
		props.put("boprops.put("bootstrap.servers", "peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092");
		props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
		props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
		
		Producer<String, String> producer = new KafkaProducer<>(props);
		try {
			for (int i=0; i<3; i++) {
				ProducerRecord<String, String> record = new ProducerRecord<>("peter-basic01", "MESSAGE - " + i);
				RecordMetaData metadata = producer.send(record, new PeterProducerCallback(record));
			}
		} catch (Exception e) {
			e.printstackTrace();
		} finally {
			producer.close();
		}
	}
}
```

위와 같이 비동기 방식으로 전송하면 빠른 전송이 가능하고, 메시지 전송이 실패한 경우라도 예외를 처리할 수 있어서 이후 에러 로그 등에 기록할 수도 있습니다.

# 3.4 컨슈머의 기본 동작과 예제 맛보기

컨슈머는 카프카의 토픽에 저장되어 있는 메시지를 가져오는 역할을 담당합니다. 컨슈머가 단순하게 카프카로부터 메시지만 가져오는 것 같지만, 내부적으로는 컨슈머 그룹, 리밸런싱 등 여러 동작을 수행합니다.

## 3.4.1 컨슈머의 기본 동작

컨슈머 크룹은 하나 이상의 컨슈머들이 모여 있는 그룹을 의미하고, 컨슈머는 반드시 컨슈머 그룹에 속하게 됩니다. 그리고 이 컨슈머 그룹은 각 파티션의 리더에게 카프카 토픽에 저장된 메시지를 가져오기 위한 요청을 보냅니다. 이때 파티션 수와 컨슈머 수(하나의 컨슈머 그룹안에 있는 컨슈머 수)는 일대일로 매핑되는 것이 이상적입니다. 

파티션 수보다 컨슈머 수가 많게 구현하는 것은 바람직한 구성이 아닙니다. 왜냐하면 컨슈머 수가 파티션 수보다 더 많다고 해서 더 빠르게 토픽의 메시지를 가져오거나 처리량이 높아지는 것이 아니라 더 많은 수의 컨슈머들이 그냥 대기 상태로만 존재하기 때문입니다. 간혹 액티브/스탠바이 개념으로 추가 컨슈머가 더 있으면 좋을 것이라고 생각할 수도 있지만, 컨슈머 그룹 내에서 리밸런싱 동작을 통해 장애가 발생한 컨슈머의 역할을 동일한 그룹에 있는 다른 컨슈머가 대신 수행하므로 굳이 장애 대비를 위한 추가 컨슈머 리소스를 할당하지 않아도 됩니다.

## 3.4.2 컨슈머의 주요 옵션

카프카에는 메시지가 잘 저장되어 있어도 관리자가 컨슈머를 어떻게 처리하고 다루느냐에 따라 컨슈머 동작에서 메시지의 중복, 유실 등 여러 가지 상황이 발생할 수 있습니다. 

컨슈머는 옵션에 따라 오토 커밋, 배치 등의 설정을 할 수 있습니다.

| 컨슈머 옵션 | 설명 |
| --- | --- |
| bootstrap.servers | 브로커의 정보를 입력합니다. |
| fetch.min.bytes | 한 번에 가져올 수 있는 최소 데이터 크기. 지정한 크기보다 작은 경우, 요청에 응답하지 않고 데이터가 누적될 때까지 기다립니다. |
| group.id | 컨슈머가 속한 컨슈머 그룹을 식별하는 식별자입니다. |
| heartbeat.interval.ms | 하트비트가 있다는 것은 컨슈머의 상태가 active임을 의미합니다. session.timeout.ms와 밀접한 관계가 있으며, session.timeout.ms 보다 낮은 값으로 설정해야 합니다. 일반적으로 1/3으로 설정합니다. |
| max.partition.fetch.bytes | 파티션당 가져올 수 있는 최대 크기를 의미합니다. |
| session.timeout.ms | 이 시간을 이용해, 컨슈머가 종료된 것인지를 판단합니다. 컨슈머는 주기적으로 하트비트를 보내야하고, 만약 이 시간 전까지 하트비트를 보내지 않았다면 해당 컨슈머는 종료된 것으로 간주하고 컨슈머 그룹에서 제외하고 리밸런싱을 시작합니다. |
| enable.auto.commit | 백그라운드로 주기적으로 오프셋을 커밋합니다. |
| auto.offset.reset | 카프카에서 초기 오프셋이 없거나 현재 오프셋이 더 이상 존재하지 않는 경우에 다음 옵션으로 reset합니다. 
- earliest: 가장 초기의 오프셋값으로 설정합니다.
- latest: 가장 마지막의 오프셋값으로 설정합니다.
- none: 이전 오프셋값을 찾지 못하면 에러를 나타냅니다. |
| fetch.max.bytes | 한 번의 가져오기 요청으로 가져올 수 있는 최대 크기입니다. |
| group.instance.id | 컨슈머의 고유한 식별자입니다. 만약 설정한다면 static 멤버로 간주되어, 불필요한 리밸런싱을 하지 않습니다. |
| isolation.level | 트랜잭션 컨슈머에서 사용되는 옵션으로, read_uncommitted는 기본값으로 모든 메시지를 읽고, read_committed는 트랜잭션이 완료된 메시지만 읽습니다. |
| max.poll.records | 한 번의 poll() 요청으로 가져오는 최대 메시지 수입니다. |
| partition.assignment.strategy | 파티션 할당 전략이며, 기본값은 range입니다. |
| fetch.max.wait.ms | fetch.min.byte에 의해 설정된 데이터보다 적은 경우 요청에 대한 응답을 기다리는 최대시간입니다. |

## 3.4.3 컨슈머 예제

컨슈머에서 메시지를 가져오는 방법은 크게 세 가지로 오토 커밋, 동기 가져오기, 비동기 가져오기가 있습니다.

### 오토 커밋

```java
public class ConsumerAuto {
	public static void main(String[] args) {
		Properties props = new Properties();
		props.put("bootstrap.servers", "peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092");
		props.put("group.id", "peter-consumer01");
		props.put("enable.auto.commit", "true");
		props.put("auto.offset.reset", "latest");
		props.put("key.deserializer", "org.apache.kafka.common.serialization.StringSerializer");
		props.put("value.deserializer", "org.apache.kafka.common.serialization.StringSerializer");
		
		KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
		consumer.subscribe(Arrays.asList("peter-basic01"));
		
		try {
			while(true) {
				ConsumerRecords<String, String> records = consumer.poll(1000);
				for (ConsumerRecord<String, String> record: records) {
					System.out.printf("Topic: %s, Partition: %d, Offset: %d, Key: %s, Received Message: %s\n", 
														record.topic(), record.partition(), record.offset(), record.key(), record.value());
				}
			}
		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			consumer.close();
		}
	}
}

```

### 동기 가져오기

```java
public class CustomSync {
	public static void main(String[] args) {
		Properties props = new Properties();
		props.put("bootstrap.servers", "peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092");
		props.put("group.id", "peter-consumer01");
		props.put("enable.auto.commit", "false");
		props.put("auto.offset.reset", "latest");
		props.put("key.deserializer", "org.apache.kafka.common.serialization.StringSerializer");
		props.put("value.deserializer", "org.apache.kafka.common.serialization.StringSerializer");
		
		KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
		consumer.subscribe(Arrays.asList("peter-basic01"));
		
		try {
			while(true) {
				ConsumerRecords<String, String> records = consumer.poll(1000);
				for (ConsumerRecord<String, String> record: records) {
					System.out.printf("Topic: %s, Partition: %d, Offset: %d, Key: %s, Received Message: %s\n", 
														record.topic(), record.partition(), record.offset(), record.key(), record.value());
				}
				consumer.commitSync();
			}

		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			consumer.close();
		}
	}
}
```

동기 방식으로 가져오는 경우 속도는 느리지만, 메시지 손실은 거의 발생하지 않습니다. 메시지 손실이란, 실제로 토픽에는 메시지가 존재하지만 잘못된 오프셋 커밋으로 인한 위치 변경으로 컨슈머가 메시지를 가져오지 못하는 경우를 ㄷ말합니다. 메시지가 손실되면 안 되는 중요한 처리 작업들은 동기 방식으로 진행하는 것을 권장합니다. 하지만 이 방법도 메시지의 중복 이슈는 피할 수 없습니다.

### 비동기 가져오기

```java
public class ConsumerAsync {
	public static void main(String[] args) {
		Properties props = new Properties();
		props.put("bootstrap.servers", "peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092");
		props.put("group.id", "peter-consumer01");
		props.put("enable.auto.commit", "false");
		props.put("auto.offset.reset", "latest");
		props.put("key.deserializer", "org.apache.kafka.common.serialization.StringSerializer");
		props.put("value.deserializer", "org.apache.kafka.common.serialization.StringSerializer");
		
		KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
		consumer.subscribe(Arrays.asList("peter-basic01"));
		
		try {
			while(true) {
				ConsumerRecords<String, String> records = consumer.poll(1000);
				for (ConsumerRecord<String, String> record: records) {
					System.out.printf("Topic: %s, Partition: %d, Offset: %d, Key: %s, Received Message: %s\n", 
														record.topic(), record.partition(), record.offset(), record.key(), record.value());
				}
				consumer.commitAsync();
			}

		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			consumer.close();
		}
	
	}

}

```

비동기 방식은 오프셋 커밋을 실패하더라도 재시도 하지 않습니다. 실패 후 재시도를 하게 되면 실제 오프셋은 뒤에 있는데도 재시도 된 오프셋부터 다시 메시지를 가져오게 될 것입니다. 

이러한 비동기 방식을 좀 더 보와하기 위해 콜백을 같이 사용하는 경우도 있습니다.

## 3.4.4 컨슈머 그룹의 이해

컨슈머는 컨슈머 그룹 안에 속한 것이 일반적인 구조로, 하나의 컨슈머 그룹 안에 여러 개의 컨슈머가 구성될 수 있습니다.  그리고 컨슈머들은 토픽의 파티션과 일대일로 매핑되어 메시지를 가져오게 됩니다.
